{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHcTRGvUmoME"
      },
      "source": [
        "# Dance Diffusion finetune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u97w34BXmust"
      },
      "source": [
        "Licensed under the MIT License\n",
        "\n",
        "Copyright (c) 2022 Zach Evans\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in\n",
        "all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
        "THE SOFTWARE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU97ZiP7nSKS"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxb-qgh0nUOf",
        "outputId": "da1239a5-c341-44fe-dcf6-85d40c99e5aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-4ee632cc-361a-5a00-031b-cb051474e47d)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Check GPU Status\n",
        "import subprocess\n",
        "simple_nvidia_smi_display = True#@param {type:\"boolean\"}\n",
        "if simple_nvidia_smi_display:\n",
        "    #!nvidia-smi\n",
        "    nvidiasmi_output = subprocess.run(['nvidia-smi', '-L'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_output)\n",
        "else:\n",
        "    #!nvidia-smi -i 0 -e 0\n",
        "    nvidiasmi_output = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_output)\n",
        "    nvidiasmi_ecc_note = subprocess.run(['nvidia-smi', '-i', '0', '-e', '0'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_ecc_note)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_mFtzHvnlJL",
        "outputId": "e79b4b8d-7320-4c70-b66a-8d49fee9fbaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Colab detected. Using Google Drive.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Prepare folders\n",
        "import subprocess, os, sys, ipykernel\n",
        "\n",
        "def gitclone(url, targetdir=None):\n",
        "    if targetdir:\n",
        "        res = subprocess.run(['git', 'clone', url, targetdir], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    else:\n",
        "        res = subprocess.run(['git', 'clone', url], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def pipi(modulestr):\n",
        "    res = subprocess.run(['pip', 'install', modulestr], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def pipie(modulestr):\n",
        "    res = subprocess.run(['git', 'install', '-e', modulestr], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def wget(url, outputdir):\n",
        "    res = subprocess.run(['wget', url, '-P', f'{outputdir}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    print(\"Google Colab detected. Using Google Drive.\")\n",
        "    is_colab = True\n",
        "    google_drive = True #@param {type:\"boolean\"}\n",
        "    #@markdown Click here if you'd like to save the diffusion model checkpoint file to (and/or load from) your Google Drive:\n",
        "    save_models_to_google_drive = True #@param {type:\"boolean\"}\n",
        "except:\n",
        "    is_colab = False\n",
        "    google_drive = False\n",
        "    save_models_to_google_drive = False\n",
        "    print(\"Google Colab not detected.\")\n",
        "\n",
        "if is_colab:\n",
        "    if google_drive is True:\n",
        "        drive.mount('/content/drive')\n",
        "        root_path = '/content/drive/MyDrive/AI/Bass_Diffusion'\n",
        "    else:\n",
        "        root_path = '/content'\n",
        "else:\n",
        "    root_path = os.getcwd()\n",
        "\n",
        "import os\n",
        "def createPath(filepath):\n",
        "    os.makedirs(filepath, exist_ok=True)\n",
        "\n",
        "initDirPath = f'{root_path}/init_audio'\n",
        "createPath(initDirPath)\n",
        "outDirPath = f'{root_path}/audio_out'\n",
        "createPath(outDirPath)\n",
        "\n",
        "if is_colab:\n",
        "    if google_drive and not save_models_to_google_drive or not google_drive:\n",
        "        model_path = '/content/models'\n",
        "        createPath(model_path)\n",
        "    if google_drive and save_models_to_google_drive:\n",
        "        model_path = f'{root_path}/models'\n",
        "        createPath(model_path)\n",
        "else:\n",
        "    model_path = f'{root_path}/models'\n",
        "    createPath(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9BS0ks1oEgP",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "!git clone https://github.com/harmonai-org/sample-generator\n",
        "!pip install /content/sample-generator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "0xq2TJzIPTcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Log in to [Weights & Biases](https://wandb.ai/) for run tracking\n",
        "!wandb login"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oxJFFEZ8CD8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/sample-generator/\n",
        "#@markdown Name for the finetune project\n",
        "NAME=\"dd-drums-finetune\"#@param {type:\"string\"}\n",
        "\n",
        "#@markdown Path to the directory of audio data to use for fine-tuning\n",
        "TRAINING_DIR=\"/content/drive/MyDrive/Audio/Drums\"#@param {type:\"string\"}\n",
        "\n",
        "#@markdown Path to the checkpoint to fine-tune\n",
        "CKPT_PATH=\"/content/drive/MyDrive/AI/models/jmann-small-190k.ckpt\"#@param {type:\"string\"}\n",
        "\n",
        "#@markdown Number of training steps between demos\n",
        "DEMO_EVERY=250 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Number of training steps between saving model checkpoints\n",
        "CHECKPOINT_EVERY=500 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Batch size to fine-tune (make it as high as it can go for your GPU)\n",
        "BATCH_SIZE=2 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Accumulate gradients over n batches, useful for training on one GPU. \n",
        "#@markdown\n",
        "#@markdown Effective batch size is BATCH_SIZE * ACCUM_BATCHES.\n",
        "ACCUM_BATCHES=4 #@param {type:\"number\"}\n",
        "\n",
        "!python3 /content/sample-generator/train_uncond.py --ckpt-path $CKPT_PATH --name $NAME --training-dir $TRAINING_DIR --sample-size 65536 --sample-rate 48000 --batch-size $BATCH_SIZE --demo-every $DEMO_EVERY --demo-steps 100 --checkpoint-every $CHECKPOINT_EVERY --num-workers 12 "
      ],
      "metadata": {
        "id": "-Q0XrS0HEmch",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "HHcTRGvUmoME"
      ],
      "name": "Finetune Dance Diffusion.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}